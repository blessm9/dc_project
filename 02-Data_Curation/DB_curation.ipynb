{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data curation\n",
    "\n",
    "Goal: Process the data from the raw database to make it ready for data analysis. This new database will be called prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'prod' already exists.\n"
     ]
    }
   ],
   "source": [
    "# Data curation\n",
    "import sqlite3\n",
    "\n",
    "# Used for pretty printing\n",
    "import pandas as pd\n",
    "\n",
    "# Creating empty data base\n",
    "con = sqlite3.connect(\"unified.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "# Enable REGEX for sqlite\n",
    "import re\n",
    "\n",
    "\n",
    "def regexp(expr, item):\n",
    "    reg = re.compile(expr)\n",
    "    return reg.search(item) is not None\n",
    "\n",
    "con.create_function(\"REGEXP\", 2, regexp)\n",
    "\n",
    "# Create new table and check for multiple executions\n",
    "cur.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name='prod'\")\n",
    "if not cur.fetchone():  # If the fetch returns None, table does not exist\n",
    "    cur.execute(\"CREATE TABLE prod AS SELECT * FROM initial\")\n",
    "    print(\"Table 'prod' created successfully.\")\n",
    "else:\n",
    "    print(\"Table 'prod' already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid sequences\n",
    "\n",
    "Check wether sequence only contains valid amino acids and no whitespaces or any other letters not being valid AA's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT *\n                FROM initial\n                WHERE seq REGEXP '[^ARNDCEQGHILKMFPSTWYVX]'; \n': no such table: initial",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: initial",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This query checks if there are any symbols other the the valid aa code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mSELECT *\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m                FROM initial\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m                WHERE seq REGEXP \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m[^ARNDCEQGHILKMFPSTWYVX]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m; \u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m  \u001b[38;5;66;03m# WHERE seq REGEXP '[^ARNDCEQGHILKMFPSTWYV]'; to not include X\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT *\n                FROM initial\n                WHERE seq REGEXP '[^ARNDCEQGHILKMFPSTWYVX]'; \n': no such table: initial"
     ]
    }
   ],
   "source": [
    "# This query checks if there are any symbols other the the valid aa code\n",
    "pd.read_sql_query(\"\"\"SELECT *\n",
    "                FROM initial\n",
    "                WHERE seq REGEXP '[^ARNDCEQGHILKMFPSTWYVX]'; \n",
    "\"\"\", con)\n",
    " # WHERE seq REGEXP '[^ARNDCEQGHILKMFPSTWYV]'; to not include X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems found in seq:\n",
    "* non capitalized letters\n",
    "* the letter X and B in seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The lower case problem\n",
    "This can be solved pretty easy by just replacing all the lowercase seqences with upper case ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "UPDATE initial\n",
    "SET seq = UPPER(seq)\n",
    "WHERE seq != UPPER(seq);\n",
    "\"\"\")\n",
    "\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The other constraints\n",
    "Idea is to add a new col called valid. This either says yes or no including the reason why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create col\n",
    "cur.execute(\"\"\"\n",
    "ALTER TABLE initial\n",
    "ADD COLUMN valid TEXT DEFAULT 'yes';\n",
    "\"\"\")\n",
    "\n",
    "# update col\n",
    "cur.execute(\"\"\"\n",
    "UPDATE initial\n",
    "SET valid = CASE \n",
    "    WHEN AB NOT IN (0, 1) THEN 'Invalid AB value'\n",
    "    WHEN dataset IS NULL THEN 'Dataset is null'\n",
    "    WHEN LENGTH(seq) < 1 OR LENGTH(seq) > 200 THEN 'Invalid seq length'\n",
    "    WHEN seq REGEXP '^[ARNDCEQGHILKMFPSTWYVX]+$' THEN valid\n",
    "    ELSE 'Invalid sequence characters'\n",
    "END;\n",
    "\"\"\")\n",
    "\n",
    "# uniqueness check\n",
    "cur.execute(\"\"\"\n",
    "UPDATE initial\n",
    "SET valid = 'Seq must be unique'\n",
    "WHERE rowid NOT IN (\n",
    "    SELECT MIN(rowid)\n",
    "    FROM initial\n",
    "    GROUP BY seq\n",
    ");\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasons why data is rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT COUNT(*),valid FROM initial GROUP BY valid\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we have engough data to just reject the 34 invalid sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates\n",
    "Before we just reject all duplicates we need to check wether they are true duplicates meaning if they are stemming from multiple datasets or just technical replicates.\n",
    "\n",
    "Definition used here:\n",
    "\n",
    "**technical replicate:** if dataset and seq is a duplicate -\n",
    "\n",
    "**duplicate:** if only seq is a duplicate but sources state the same AB\n",
    "\n",
    "**contradictory duplicate** matching seq different source and different AB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def identify_duplicates():   \n",
    "    # Step 1: Identify Technical Replicates\n",
    "    cur.execute(\"\"\"\n",
    "    UPDATE initial\n",
    "    SET valid = 'technical replicate'\n",
    "    WHERE seq IN (\n",
    "        SELECT seq\n",
    "        FROM initial\n",
    "        GROUP BY seq, dataset\n",
    "        HAVING COUNT(*) > 1\n",
    "    );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Step 2: Identify Duplicates (same seq, multiple datasets, same AB)\n",
    "    cur.execute(\"\"\"\n",
    "    UPDATE initial\n",
    "    SET valid = 'duplicate'\n",
    "    WHERE seq IN (\n",
    "        SELECT seq\n",
    "        FROM initial\n",
    "        GROUP BY seq, AB\n",
    "        HAVING COUNT(DISTINCT dataset) > 1\n",
    "    ) AND valid != 'technical replicate';\n",
    "    \"\"\")\n",
    "    \n",
    "    # Step 3: Identify Contradictory Duplicates (same seq, different AB in different datasets)\n",
    "    cur.execute(\"\"\"\n",
    "    UPDATE initial\n",
    "    SET valid = 'contradictory duplicate'\n",
    "    WHERE seq IN (\n",
    "        SELECT seq\n",
    "        FROM initial\n",
    "        GROUP BY seq\n",
    "        HAVING COUNT(DISTINCT AB) > 1 AND COUNT(DISTINCT dataset) > 1\n",
    "    ) AND valid NOT IN ('technical replicate', 'duplicate');\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "identify_duplicates()\n",
    "#pd.read_sql_query(\"SELECT * FROM initial WHERE valid = 'contradictory duplicate' ORDER BY seq;\", con).to_excel(\"contradictions.xlsx\")\n",
    "pd.read_sql_query(\"SELECT COUNT(*), valid FROM initial GROUP BY valid\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adressing contradictory duplicates\n",
    "Theese stem from negative data sources (i.e uniprot). We can reject the ones from uniprot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "UPDATE initial\n",
    "SET AB = 1\n",
    "WHERE dataset = 'uniprot_swissprot.fasta' AND valid = 'contradictory duplicate';\n",
    "\"\"\")\n",
    "\n",
    "identify_duplicates()\n",
    "pd.read_sql_query(\"SELECT COUNT(*), valid FROM initial GROUP BY valid\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means all duplicates stem from the uniprot data base. We have no other duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adressing Invalid sequences and technical duplicates\n",
    "we just remove them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "DELETE FROM initial\n",
    "WHERE NOT seq REGEXP '^[ARNDCEQGHILKMFPSTWYVX]+$' OR valid = 'technical replicate';\n",
    "\"\"\")\n",
    "\n",
    "identify_duplicates()\n",
    "pd.read_sql_query(\"SELECT COUNT(*), valid FROM initial GROUP BY valid\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge duplicates\n",
    "To remove the duplicates but keep the information we will merge theese rows containing the duplicates.\n",
    "\n",
    "From here on we will work with a new table which enforces data integrity. The table enforces the folloing conditions:\n",
    "\n",
    "\n",
    " * only valid amino acid seq\n",
    " * AB only being 0 or 1\n",
    " * AB cant bo 0\n",
    " * dataset must not be null\n",
    " * seq length between 1 and 200\n",
    " * seq must be unique and not null\n",
    "\n",
    "I have decided to designate seq as database keys. This enforces uniqueness, non nullabilty and improves lookup performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM  initial WHERE valid = 'duplicate' ORDER BY seq LIMIT 4;\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new table for the merged results\n",
    "try: \n",
    "    cur.execute(\"\"\" DROP TABLE prod; \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS prod (\n",
    "    id TEXT,\n",
    "    name TEXT,\n",
    "    AB INTEGER NOT NULL CHECK (AB IN (0, 1)),\n",
    "    description TEXT,\n",
    "    OX TEXT,\n",
    "    source TEXT NOT NULL,\n",
    "    seq TEXT PRIMARY KEY CHECK (seq = UPPER(seq) AND seq REGEXP '^[ARNDCEQGHILKMFPSTWYVX]+$'),\n",
    "    valid TEXT\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Insert aggregated data into the new table INSERT INTO prod(id, name, AB, description, OX, source, seq, valid)\n",
    "cur.execute(\"\"\"\n",
    "INSERT INTO prod(id, name, AB, description, OX, source, seq, valid)\n",
    "SELECT \n",
    "    GROUP_CONCAT(id, '; ') AS id,\n",
    "    GROUP_CONCAT(name, '; ') AS name,\n",
    "    AB,\n",
    "    GROUP_CONCAT(description, '; ') AS description,\n",
    "    GROUP_CONCAT(OX, '; ') AS OX,\n",
    "    GROUP_CONCAT(dataset, '; ') AS source,\n",
    "    UPPER(seq) AS seq,\n",
    "    'yes - merged duplicate' AS valid\n",
    "FROM initial\n",
    "WHERE valid = 'duplicate' AND seq REGEXP '^[ARNDCEQGHILKMFPSTWYVX]+$'\n",
    "GROUP BY seq;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT * FROM  prod;\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "830 duplicates successfully merged into 415 concatenated rows.\n",
    "\n",
    "# Merge the rest\n",
    "\n",
    "Add valid sequences into valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "INSERT INTO prod\n",
    "SELECT id, name, AB, description, OX, dataset, seq, valid FROM initial\n",
    "WHERE valid = 'yes';\n",
    "\"\"\")\n",
    "\n",
    "pd.read_sql_query(\"SELECT * FROM  prod;\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final health check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql_query(\"SELECT COUNT(*), valid FROM prod GROUP BY valid\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and commit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"DROP TABLE initial\")\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
