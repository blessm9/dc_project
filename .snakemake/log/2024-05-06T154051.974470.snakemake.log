Building DAG of jobs...
Provided cores: 10
Rules claiming more threads will be scaled down.
Singularity containers: ignored
Job stats:
job                count
---------------  -------
all                    1
create_database        1
total                  2

Select jobs to execute...
Execute 1 jobs...

[Mon May  6 15:40:52 2024]
localrule create_database:
    input: 01 - Data Extraction/data_pos_neg.csv
    output: 02 - Data Curation/unified.db
    jobid: 1
    reason: Code has changed since last execution
    resources: tmpdir=C:\Users\Etienne\AppData\Local\Temp

RuleException:
CalledProcessError in file Z:\projects\dc_project\Snakefile, line 13:
Command 'jupyter-nbconvert --log-level ERROR --execute  --to notebook --ExecutePreprocessor.timeout=-1 "Z:/projects/dc_project/.snakemake/scripts/tmpvbbaljm5.DB creation.ipynb"' returned non-zero exit status 1.
[Mon May  6 15:41:00 2024]
Error in rule create_database:
    jobid: 1
    input: 01 - Data Extraction/data_pos_neg.csv
    output: 02 - Data Curation/unified.db

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake\log\2024-05-06T154051.974470.snakemake.log
WorkflowError:
At least one job did not complete successfully.
